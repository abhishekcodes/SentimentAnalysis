'''POSITIVE SCORE
NEGATIVE SCORE
POLARITY SCORE
SUBJECTIVITY SCORE
AVG SENTENCE LENGTH
PERCENTAGE OF COMPLEX WORDS
FOG INDEX
AVG NUMBER OF WORDS PER SENTENCE
COMPLEX WORD COUNT
WORD COUNT
SYLLABLE PER WORD
PERSONAL PRONOUNS
AVG WORD LENGTH'''

#stop words removal using nltk
#from NLTKprocess import dataToProcess
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import pandas as pd
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# article_data = dataToProcess(i=0)
# print(article_data)

example = r'When people hear AI they often think about sentient robots and magic boxes.' \
          r' AI today is much more mundane and simple—but that doesn’t mean it’s not powerful.' \
          # r' Another misconception is that high-profile research projects can be applied directly to any business situation.' \
          # r' AI done right can create an extreme return on investments (ROIs)—for instance through automation or precise prediction. ' \
          # r'But it does take thought, time, and proper implementation. ' \
          # r'We have seen that success and value generated by AI projects are increased when there is a grounded understanding and expectation of what' \
          # r' the technology can deliver from the C-suite down. ' \
          # r'Artificial Intelligence (AI) is a science and a set of computational technologies that are inspired by—but typically operate quite differently from the ways people use' \
          # r' their nervous systems and bodies to sense, learn, reason and take action.' \
          # r' Lately there has been a big rise in the day-to-day use of machines powered by AI.' \
          # r' These machines are wired using cross-disciplinary approaches based on mathematics, computer science, statistics, psychology, and more.' \
          # r' Virtual assistants are becoming more common, most of the web shops predict your purchases, many companies make use of chatbots in their customer service' \
          # r' and many companies use algorithms to detect fraud. ' \
          # r'AI and Deep Learning technology employed in office entry systems will bring proper time tracking of each employee.' \
          # r' As this system tries to learn each person with an image processing technology whose data is feed forwarded to a deep learning model' \
          # r' where Deep learning isn’t an algorithm per se, but rather a family of algorithms that implements deep networks (many layers).' \
          # r' These networks are so deep that new methods of computation, such as graphics processing units (GPUs), are required to train them,' \
          # r' in addition to clusters of compute nodes. So using deep learning we can take detect the employee using face and person recognition scan and through' \
          # r' which login, logout timing is recorded. Using an AI system we can even identify each employee’s entry time, their working hours,' \
          # r' non-working hours by tracking the movement of an employee in the office so that system can predict and report HR for the salary for each employee based on their working hours.' \
          # r' Our system can take feed from CCTV to track movements of employees ' \
          # r'and this system is capable of recognizing a person even he/she is being masked as in this pandemic situation by taking their iris scan.' \
          # r' With this system installed inside the office, the following are some of the benefits.'


word_tokens = word_tokenize(example)
#print(len(word_tokens))
stop_words = set(stopwords.words('english'))
filtered_words = []

for w in word_tokens:
    if w not in stop_words:
        filtered_words.append(w)


print(len(filtered_words))

# vedar = SentimentIntensityAnalyzer()
#
# f = lambda: vedar.polarity_score(words)['compound']
# df['compound'] = df['words'].apply(f)
# print(df.head())

# from nltk.sentiment import SentimentIntensityAnalyzer
# senti = SentimentIntensityAnalyzer()
# score = senti.polarity_scores()


#stemming
#normalizing words into its base form
from nltk.stem import PorterStemmer
pst = PorterStemmer()
for word in filtered_words:
    #print(pst.stem(word))

#three types of stemmer Porter/lancaster/snowball
#when stemming does not work lemmetization can be done


#lemmatization
#from nltk.stem import wordnet
# from nltk.stem import WordNetLemmatizer
# word_lem = WordNetLemmatizer()
#
# print(word_lem.lemmatize('Beautiful'))

#to remove punctuation etc from paragrapgh
import re
punctuation.compile(r'[-?!,.:;()|0-9]')
post_cleaning = []
for words in filtered_words:
    word = punctuation.sub("",words)
    if len(word)>0:
        post_cleaning.append(word)